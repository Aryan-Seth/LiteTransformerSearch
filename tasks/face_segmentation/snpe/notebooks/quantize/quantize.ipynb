{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Azure Machine Learning Workspace \n",
    "import json\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# make sure we have a scripts dir for the code to run our jobs.\n",
    "import os\n",
    "scripts_dir = \"./scripts\"\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "\n",
    "config_file = \".azureml/config.json\"\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "for required_key in ['subscription_id', 'resource_group', 'workspace_name', 'storage_account_key', 'storage_account_name']:\n",
    "    if not required_key in config:\n",
    "        print(f\"### Error: please add a {required_key} to {config_file}\")\n",
    "\n",
    "storage_account_key = config['storage_account_key']    \n",
    "storage_account_name = config['storage_account_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .azureml\\config.json\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=credential,\n",
    "    path='./.azureml/config.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with name face_segmentation_dataset was registered to workspace, the dataset version is 1.0.1\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "face_data = Data(\n",
    "    name=\"face_segmentation_dataset\",\n",
    "    path=\"https://nasfacemodels.blob.core.windows.net/downloads/099000.zip\",\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Dataset for quantizing the model\",\n",
    "    tags={\"source_type\": \"web\", \"source\": \"azure\"},\n",
    "    version=\"1.0.1\",\n",
    ")\n",
    "\n",
    "face_data = ml_client.data.create_or_update(face_data)\n",
    "print(\n",
    "    f\"Dataset with name {face_data.name} was registered to workspace, the dataset version is {face_data.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'nassnpe205test', 'description': 'Datastore pointing to our dataset container.', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace/datastores/nassnpe205test', 'Resource__source_path': None, 'base_path': 'd:\\\\git\\\\microsoft\\\\image_segmentation\\\\snpe\\\\notebooks\\\\quantize', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017746404D30>, 'credentials': {'type': 'account_key'}, 'container_name': 'models', 'account_name': 'nassnpe205test', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AzureBlobDatastore\n",
    "from azure.ai.ml.entities._credentials import AccountKeyConfiguration\n",
    "\n",
    "# Register the blob store container for storing our models\n",
    "data_store = AzureBlobDatastore(\n",
    "    name=\"nassnpe205test\",\n",
    "    description=\"Datastore pointing to our dataset container.\",\n",
    "    account_name=storage_account_name,\n",
    "    container_name=\"models\",\n",
    "    credentials=AccountKeyConfiguration(\n",
    "        account_key=storage_account_key\n",
    "    ),\n",
    ")\n",
    "\n",
    "ml_client.create_or_update(data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path shown in the Data asset we created to point to this model...\n",
    "subscription = ml_client.subscription_id\n",
    "rg = ml_client.resource_group_name\n",
    "ws_name = ml_client.workspace_name\n",
    "\n",
    "#datastore_path = f\"azureml://datastores/nasfacemodels/paths/Deci1\"\n",
    "datastore_path = f\"azureml://datastores/nassnpe205test/paths/Deci2\"\n",
    " \n",
    "model_path = f\"{datastore_path}/deci_optimized_2.onnx\"\n",
    "dlc_path = f\"{datastore_path}/model.dlc\"\n",
    "quant_dlc_path = f\"{datastore_path}/model.quant.dlc\"\n",
    "dlc_info_path = f\"{datastore_path}/model.info.txt\"\n",
    "quant_dlc_info_path = f\"{datastore_path}/model.quant.info.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found your Kubernetes cluster named snpe-compute, awesome!\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "snpe_cluster = \"snpe-compute\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    cpu_cluster = ml_client.compute.get(snpe_cluster)\n",
    "    print(\n",
    "        f\"Found your Kubernetes cluster named {snpe_cluster}, awesome!\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(f\"Computer cluster named {snpe_cluster} was not found ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name quantization is registered to workspace, the environment version is 1.3\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"quantization\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for running the quantizer pipeline\",    \n",
    "    image=\"snpecontainerregistry001.azurecr.io/snpe-2.5.0\",\n",
    "    version=\"1.3\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "data_prep_component = command(\n",
    "    name=\"data_prep\",\n",
    "    display_name=\"Data preparation for quantization\",\n",
    "    description=\"Unzips the dataset and converts to .bin format\",\n",
    "    inputs={\n",
    "        \"data\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "    outputs= {\n",
    "        \"quant_data\": Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 data_prep.py \\\n",
    "            --data ${{inputs.data}} \\\n",
    "            --output ${{outputs.quant_data}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_component = command(\n",
    "    name=\"convert\",\n",
    "    display_name=\"Convert .onnx to .dlc\",\n",
    "    description=\"Converts the onnx model to dlc format\",\n",
    "    inputs={\n",
    "        \"model\": Input(type=\"uri_file\")\n",
    "    },\n",
    "    outputs= {\n",
    "        \"dlc\": Output(type=\"uri_file\", path=dlc_path, mode=\"rw_mount\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 convert.py \\\n",
    "            --model ${{inputs.model}} \\\n",
    "            --output ${{outputs.dlc}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_component = command(\n",
    "    name=\"quantize_model\",\n",
    "    display_name=\"Quantize the Model\",\n",
    "    description=\"Runs snpe-dlc-quant on the model using the prepared quantization dataset\",\n",
    "    inputs={\n",
    "        \"data\": Input(type=\"uri_folder\"),\n",
    "        \"list_file\": Input(type=\"string\"),\n",
    "        \"model\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "    outputs= {\n",
    "        \"quant_model\": Output(type=\"uri_file\", path=quant_dlc_path, mode=\"rw_mount\")\n",
    "    },\n",
    "\n",
    "    # The source folder of the component\n",
    "    code=scripts_dir,\n",
    "    command=\"\"\"python3 quantize.py \\\n",
    "            --data ${{inputs.data}} \\\n",
    "            --list_file ${{inputs.list_file}} \\\n",
    "            --model ${{inputs.model}} \\\n",
    "            --output ${{outputs.quant_model}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_component(output_path):\n",
    "    return command(\n",
    "        name=\"model_info\",\n",
    "        display_name=\"Get model metrics\",\n",
    "        description=\"Runs snpe-dlc-info on the input .dlc model\",\n",
    "        inputs={\n",
    "            \"model\": Input(type=\"uri_folder\")\n",
    "        },\n",
    "        outputs= {\n",
    "            \"info\": Output(type=\"uri_file\", path=output_path, mode=\"rw_mount\")\n",
    "        },\n",
    "\n",
    "        # The source folder of the component\n",
    "        code=scripts_dir,\n",
    "        command=\"\"\"python3 dlc_info.py \\\n",
    "                --model ${{inputs.model}} \\\n",
    "                --output ${{outputs.info}} \\\n",
    "                \"\"\",\n",
    "        environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=snpe_cluster,\n",
    "    description=\"Quantization pipeline\",\n",
    ")\n",
    "def quantization_pipeline(\n",
    "    pipeline_job_data_input,\n",
    "    model_input\n",
    "):\n",
    "    # using data_prep_function like a python call with its own inputs\n",
    "    data_prep_job = data_prep_component(\n",
    "        data=pipeline_job_data_input\n",
    "    )\n",
    "\n",
    "    # convert onnx to dlc\n",
    "    convert_job = convert_component(\n",
    "        model=model_input\n",
    "    )\n",
    "\n",
    "    # get the dlc info on the converted model\n",
    "    info_job = info_component(dlc_info_path)(\n",
    "        model=convert_job.outputs.dlc\n",
    "    )\n",
    "\n",
    "    # quantize the dlc model\n",
    "    quant_job = quant_component(\n",
    "        data=data_prep_job.outputs.quant_data,\n",
    "        list_file='input_list.txt',\n",
    "        model=convert_job.outputs.dlc\n",
    "    )\n",
    "\n",
    "    # get the dlc info on quantized model\n",
    "    info_job = info_component(quant_dlc_info_path)(\n",
    "        model=quant_job.outputs.quant_model\n",
    "    )\n",
    "\n",
    "    # a pipeline returns a dictionary of outputs\n",
    "    # keys will code for the pipeline output identifier\n",
    "    return {\n",
    "        \"pipeline_job_model\": convert_job.outputs.dlc,\n",
    "        \"pipeline_job_quant_model\": quant_job.outputs.quant_model,\n",
    "        \"pipeline_job_info\": info_job.outputs.info\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate the pipeline with the parameters of our choice\n",
    "pipeline = quantization_pipeline(\n",
    "    pipeline_job_data_input=Input(type=\"uri_file\", path=face_data.path),\n",
    "    model_input=Input(type=\"uri_file\", path=model_path)\n",
    ")\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"quantization_test_run\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.services[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.download(pipeline_job.name, output_name='pipeline_job_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: strong_pasta_wgv176q8tw\n",
      "display_name: quantization_pipeline\n",
      "description: Quantization pipeline\n",
      "type: pipeline\n",
      "inputs:\n",
      "  pipeline_job_data_input:\n",
      "    mode: ro_mount\n",
      "    type: uri_file\n",
      "    path: azureml:https://nasfacemodels.blob.core.windows.net/downloads/099000.zip\n",
      "  model_input:\n",
      "    mode: ro_mount\n",
      "    type: uri_file\n",
      "    path: azureml://datastores/nassnpe205test/paths/Deci2/deci_optimized_2.onnx\n",
      "outputs:\n",
      "  pipeline_job_model:\n",
      "    mode: rw_mount\n",
      "    type: uri_file\n",
      "    path: azureml://datastores/nassnpe205test/paths/Deci2/model.dlc\n",
      "  pipeline_job_quant_model:\n",
      "    mode: rw_mount\n",
      "    type: uri_file\n",
      "    path: azureml://datastores/nassnpe205test/paths/Deci2/model.quant.dlc\n",
      "  pipeline_job_info:\n",
      "    mode: rw_mount\n",
      "    type: uri_file\n",
      "    path: azureml://datastores/nassnpe205test/paths/Deci2/model.quant.info.txt\n",
      "jobs:\n",
      "  data_prep_job:\n",
      "    type: command\n",
      "    inputs:\n",
      "      data:\n",
      "        path: ${{parent.inputs.pipeline_job_data_input}}\n",
      "    outputs:\n",
      "      quant_data:\n",
      "        mode: rw_mount\n",
      "        type: uri_folder\n",
      "    component: azureml:azureml_anonymous:27028d4f-0db8-49a6-a997-74422e5a037b\n",
      "  convert_job:\n",
      "    type: command\n",
      "    inputs:\n",
      "      model:\n",
      "        path: ${{parent.inputs.model_input}}\n",
      "    outputs:\n",
      "      dlc: ${{parent.outputs.pipeline_job_model}}\n",
      "    component: azureml:azureml_anonymous:d8fc98af-0f29-4b27-98ef-3993a109b122\n",
      "  info_job_1:\n",
      "    type: command\n",
      "    inputs:\n",
      "      model:\n",
      "        path: ${{parent.jobs.convert_job.outputs.dlc}}\n",
      "    outputs:\n",
      "      info:\n",
      "        mode: rw_mount\n",
      "        type: uri_file\n",
      "        path: azureml://datastores/nassnpe205test/paths/Deci2/model.info.txt\n",
      "    component: azureml:azureml_anonymous:d0525a94-b93d-4301-8cc3-1ed669cf4108\n",
      "  quant_job:\n",
      "    type: command\n",
      "    inputs:\n",
      "      list_file: input_list.txt\n",
      "      data:\n",
      "        path: ${{parent.jobs.data_prep_job.outputs.quant_data}}\n",
      "      model:\n",
      "        path: ${{parent.jobs.convert_job.outputs.dlc}}\n",
      "    outputs:\n",
      "      quant_model: ${{parent.outputs.pipeline_job_quant_model}}\n",
      "    component: azureml:azureml_anonymous:04f22241-0aea-45a9-949a-3204e076edc2\n",
      "  info_job:\n",
      "    type: command\n",
      "    inputs:\n",
      "      model:\n",
      "        path: ${{parent.jobs.quant_job.outputs.quant_model}}\n",
      "    outputs:\n",
      "      info: ${{parent.outputs.pipeline_job_info}}\n",
      "    component: azureml:azureml_anonymous:d0525a94-b93d-4301-8cc3-1ed669cf4108\n",
      "services:\n",
      "  Tracking:\n",
      "    endpoint: azureml://westus2.api.azureml.ms/mlflow/v1.0/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace?\n",
      "    job_service_type: Tracking\n",
      "  Studio:\n",
      "    endpoint: https://ml.azure.com/runs/strong_pasta_wgv176q8tw?wsid=/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourcegroups/snpe-aml-rg/workspaces/snpe-aml-workspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "    job_service_type: Studio\n",
      "compute: azureml:snpe-compute\n",
      "status: Preparing\n",
      "creation_context:\n",
      "  created_at: '2023-03-01T01:23:51.345924+00:00'\n",
      "  created_by: Chris Lovett\n",
      "  created_by_type: User\n",
      "experiment_name: quantization_test_run\n",
      "properties:\n",
      "  mlflow.source.git.repoURL: git@ssh.dev.azure.com:v3/msresearch/archai/image_segmentation\n",
      "  mlflow.source.git.branch: main\n",
      "  mlflow.source.git.commit: 6819790b2144d222d3f24870e213728eeebb11e9\n",
      "  azureml.git.dirty: 'True'\n",
      "  azureml.DevPlatv2: 'true'\n",
      "  azureml.runsource: azureml.PipelineRun\n",
      "  runSource: MFE\n",
      "  runType: HTTP\n",
      "  azureml.parameters: '{}'\n",
      "  azureml.continue_on_step_failure: 'False'\n",
      "  azureml.continue_on_failed_optional_input: 'True'\n",
      "  azureml.defaultComputeName: snpe-compute\n",
      "  azureml.defaultDataStoreName: workspaceblobstore\n",
      "  azureml.pipelineComponent: pipelinerun\n",
      "id: azureml:/subscriptions/c8b7f913-60fb-4759-a310-fc5630e56f99/resourceGroups/snpe-aml-rg/providers/Microsoft.MachineLearningServices/workspaces/snpe-aml-workspace/jobs/strong_pasta_wgv176q8tw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "799abcba35f70097d02fca042963180a03ec3451fe1b7671ac5d22383cd0232c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
